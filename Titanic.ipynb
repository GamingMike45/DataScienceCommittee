{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GamingMike45/DataScienceCommittee/blob/main/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pit009o3eaQb",
        "outputId": "131ca239-3918-4ce6-aaa2-53edfeec0c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.42.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2023.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "from re import T\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# how to use google drive #\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# takes the training data spreadsheet (csv) and puts it into two panda arrays #\n",
        "trainData = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data Science/Competitions/Titanic/train.csv\")\n",
        "testData = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data Science/Competitions/Titanic/test.csv\")\n",
        "\n",
        "\"\"\"The funtions bellow act on the data\"\"\"\n",
        "# just prints the data\n",
        "def printData():\n",
        "  #pd.set_option(\"display.max_rows\", None)\n",
        "  print(f\"Train data=\\n{trainData}\")\n",
        "  print(f\"Test data=\\n{testData}\")\n",
        "\n",
        "# makes the column Family column which is the sum of Sibsp (siblingings/spouses) and Parch (Parens/Children)\n",
        "def family(trainData, testData):\n",
        "  trainData[\"Family\"] = trainData[\"SibSp\"] + trainData[\"Parch\"]\n",
        "  testData[\"Family\"] = testData[\"SibSp\"] + testData[\"Parch\"]\n",
        "\n",
        "  print(\"   Created 'Family' column.\")\n",
        "\n",
        "\n",
        "# makes the column Last Name column which is just the peroson last name\n",
        "def lastName(trainData, testData):\n",
        "  trainData[\"LastName\"] = trainData[\"Name\"].str.split(',').str[0]\n",
        "  testData[\"LastName\"] = testData[\"Name\"].str.split(',').str[0]\n",
        "\n",
        "  print(\"   Created 'LastName' column.\")\n",
        "\n",
        "def makeFamCodes(trainData, testData):\n",
        "  trainNameSet = set(trainData[\"LastName\"])\n",
        "  testNameSet = set(testData[\"LastName\"])\n",
        "\n",
        "  print(f\"THIS IS MY SET {trainNameSet}\")\n",
        "\n",
        "  trainData[\"FamCode\"] = ''\n",
        "  testData[\"FamCode\"] = ''\n",
        "\n",
        "  i = 0\n",
        "  for name in trainNameSet:\n",
        "    trainData[\"FamCode\"] += trainData[\"LastName\"].apply(lambda s: str(i) if s == name else \"\")\n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "  for name in testNameSet:\n",
        "    testData[\"FamCode\"] += testData[\"LastName\"].apply(lambda s: str(i) if s == name else \"\")\n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "\n",
        "# FILLING in NULLS #\n",
        "def wrangleQ0(trainData, testData):\n",
        " # Extract numerical part from \"Cabin\" column\n",
        "  trainData['Cabin'] = trainData['Cabin'].str.extract('(\\d+)')\n",
        "  testData['Cabin'] = testData['Cabin'].str.extract('(\\d+)')\n",
        "\n",
        "# Convert numerical part to numeric type\n",
        "  trainData['Cabin'] = pd.to_numeric(trainData['Cabin'], errors='coerce')\n",
        "  testData['Cabin'] = pd.to_numeric(testData['Cabin'], errors='coerce')\n",
        "\n",
        "# Replace missing values in \"Cabin\" with mean\n",
        "  trainData['Cabin'].fillna(trainData['Cabin'].mean(), inplace=True)\n",
        "  testData['Cabin'].fillna(testData['Cabin'].mean(), inplace=True)\n",
        "\n",
        "  trainData[\"Age\"] = trainData[\"Age\"].fillna(trainData[\"Age\"].mean())\n",
        "  testData[\"Age\"] = testData[\"Age\"].fillna(testData[\"Age\"].mean())\n",
        "\n",
        "  trainData[\"Fare\"] = trainData[\"Fare\"].fillna(trainData[\"Fare\"].mean())\n",
        "  testData[\"Fare\"] = testData[\"Fare\"].fillna(testData[\"Fare\"].mean())\n",
        "\n",
        "  print(\"   Nulls Filled.\")\n",
        "\n",
        "\n",
        "# Remove rows with nulls in them #\n",
        "def wrangleDelNull(trainData, testData):\n",
        "  trainData.dropna(inplace=True)\n",
        "  testData.dropna(inplace=True)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def wrangleNorm(trainData, testData, exclude=[]):\n",
        "  # change this to do all numeric columns!\n",
        "  tempDF = testData.select_dtypes(include=np.number)\n",
        "  columns = []\n",
        "\n",
        "  for col in tempDF.columns:\n",
        "    if (col not in exclude):\n",
        "      columns = columns + [col]\n",
        "\n",
        "  for col in columns:\n",
        "      trainData[col] = (trainData[col] - trainData[col].min()) / (trainData[col].max() - trainData[col].min())\n",
        "      testData[col] = (testData[col] - testData[col].min()) / (testData[col].max() - testData[col].min())\n",
        "\n",
        "  print(\"   Normalized numeric columns.\")\n",
        "\n",
        "\n",
        "def printData():\n",
        "  print(f\"Train data=\\n{trainData}\")\n",
        "  print(f\"Test data=\\n{testData}\")\n",
        "\n",
        "\n",
        "!pip install tensorflow_decision_forests\n",
        "import tensorflow_decision_forests as tfdf\n",
        "# This predicts importance of our features #\n",
        "def predictImportance(trainData):\n",
        "    tfDataSet = tfdf.keras.pd_dataframe_to_tf_dataset(trainData, label='Survived')\n",
        "\n",
        "    model = tfdf.keras.RandomForestModel()\n",
        "    model.fit(tfDataSet)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# we probably dont need all these #\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "# This tests the models #\n",
        "def testModels(trainData,features):\n",
        "    print(f\"\\n{features}\")\n",
        "    # what we want to predict #\n",
        "    y = trainData[\"Survived\"]\n",
        "\n",
        "    # Change Categorical to numeric #\n",
        "    X = pd.get_dummies(trainData[features])\n",
        "\n",
        "    names = [\"RandomForest200\",\n",
        "         \"LinearSVC\",\n",
        "         \"MultinomialNB\",\n",
        "         \"Logistic\",\n",
        "         \"KNN5\",\n",
        "         \"SVCLinear\",\n",
        "         \"SVCgamma2\",\n",
        "         \"DecisionTree5\",\n",
        "         #\"RandomForest5-10\",\n",
        "         #\"MLP-2000-1000-500-100\",\n",
        "         \"AdaBoost\",\n",
        "         \"HistGradientBoost\",\n",
        "         \"GradientBoosting\",  # New model\n",
        "         \"Bagging\"            # New model\n",
        "        ]\n",
        "\n",
        "    abrevNames = [\"RF2\",\n",
        "         \"LSVC\",\n",
        "         \"MNB\",\n",
        "         \"Log\",\n",
        "         \"KNN5\",\n",
        "         \"SVCL\",\n",
        "         \"SVCg\",\n",
        "         \"DT5\",\n",
        "         #\"RF51\",\n",
        "         #\"MLP\",\n",
        "         \"AB\",\n",
        "         \"HGB\",\n",
        "         \"GB\",    # New model\n",
        "         \"Bag\"    # New model\n",
        "        ]\n",
        "\n",
        "    models = [\n",
        "        RandomForestClassifier(n_estimators=1000, max_depth=7, random_state=0),\n",
        "        LinearSVC(max_iter=500, dual=False),\n",
        "        MultinomialNB(),\n",
        "        LogisticRegression(random_state=5),\n",
        "        KNeighborsClassifier(n_neighbors=6, weights=\"uniform\"),\n",
        "        SVC(kernel=\"linear\", C=2),\n",
        "        SVC(gamma=0.34, C=2),\n",
        "        DecisionTreeClassifier(max_depth=15),\n",
        "        #RandomForestClassifier(n_estimators=750, max_depth=7, max_features=3),\n",
        "        #MLPClassifier(hidden_layer_sizes=(2000,1000,500,100)),\n",
        "        #MLPClassifier(hidden_layer_sizes=(100,50,10)),\n",
        "        AdaBoostClassifier(),\n",
        "        HistGradientBoostingClassifier(categorical_features=[]),\n",
        "        GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=.1),  # New model\n",
        "        BaggingClassifier(n_estimators=300)            # New model\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    i = 0\n",
        "    for model in models:\n",
        "        kfold = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "        model_name = names[i]\n",
        "        i = i + 1\n",
        "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "        results.append(cv_results)\n",
        "        print('%s: %f (%f)' % (model_name, cv_results.mean(), cv_results.std()))\n",
        "\n",
        "    plt.boxplot(results, labels=abrevNames)\n",
        "    plt.title('Algorithm Comparison')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def outPrediction(trainData,testData):\n",
        "    # what we want to predict #\n",
        "    y = trainData[\"Survived\"]\n",
        "\n",
        "    # features that mater!! #\n",
        "    features = [\"Fare\",\"Age\",'Pclass','Ticket','Embark',\"Cabin\"]\n",
        "\n",
        "    # Change Categorical to numeric #\n",
        "    X = pd.get_dummies(trainData[features])\n",
        "    XTest = pd.get_dummies(testData[features])\n",
        "\n",
        "    model = HistGradientBoostingClassifier(categorical_features=[])\n",
        "    model.fit(X, y)\n",
        "\n",
        "    cv_results = cross_val_score(model, X, y, scoring='accuracy')\n",
        "    result = cv_results\n",
        "    name = \"Hist\"\n",
        "    print()\n",
        "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
        "    print()\n",
        "\n",
        "    predictions = model.predict(XTest)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def outputPredictionsList(trainData,testData,features):\n",
        "    print(f\"   Using Features: {features}\")\n",
        "    # what we want to predict #\n",
        "    y = trainData[\"Survived\"]\n",
        "\n",
        "    # Change Categorical to numeric #\n",
        "    X = pd.get_dummies(trainData[features])\n",
        "    XTest = pd.get_dummies(testData[features])\n",
        "\n",
        "    models = [\n",
        "        RandomForestClassifier(n_estimators=1000, max_depth=7, random_state=0),\n",
        "        LinearSVC(max_iter=500, dual=False),\n",
        "        MultinomialNB(),\n",
        "        LogisticRegression(random_state=5),\n",
        "        KNeighborsClassifier(n_neighbors=6, weights=\"uniform\"),\n",
        "        SVC(kernel=\"linear\", C=2),\n",
        "        SVC(gamma=0.34, C=2),\n",
        "        DecisionTreeClassifier(max_depth=15),\n",
        "        #RandomForestClassifier(n_estimators=750, max_depth=7, max_features=3),\n",
        "        #MLPClassifier(hidden_layer_sizes=(2000,1000,500,100)),\n",
        "        #MLPClassifier(hidden_layer_sizes=(100,50,10)),\n",
        "        AdaBoostClassifier(),\n",
        "        HistGradientBoostingClassifier(categorical_features=[]),\n",
        "        GradientBoostingClassifier(n_estimators = 300, max_depth=3, learning_rate=.1),  # New model\n",
        "        BaggingClassifier(n_estimators=300)            # New model\n",
        "    ]\n",
        "\n",
        "    predictionsList = []\n",
        "\n",
        "    for model in models:\n",
        "        model.fit(X, y)\n",
        "        prediction = model.predict(XTest)\n",
        "        predictionsList.append(prediction)\n",
        "\n",
        "    return np.array(predictionsList)\n",
        "\n",
        "\n",
        "def outputConcensus(preditcionsList):\n",
        "  concensus = np.mean(predictionsList, axis=0)\n",
        "  #print(concensus)\n",
        "  return (np.rint(concensus)).astype(int)\n",
        "\n",
        "\n",
        "# Create an output dataframe and write it to csv file #\n",
        "def modelToCSV(testData,prediction):\n",
        "    output = pd.DataFrame({'PassengerId': testData.PassengerId, \"Survived\": prediction})\n",
        "    output.to_csv('/content/drive/MyDrive/Colab Notebooks/Data Science/Competitions/Titanic/submission.csv', index=False)\n",
        "\n",
        "    # just so we can see the submission in the console #\n",
        "    submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Science/Competitions/Titanic/submission.csv')\n",
        "    print(submission)\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0dbyBImdaUe",
        "outputId": "763acfb2-d271-427c-ba86-b16608be4a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Wrangling...\n",
            "   Nulls Filled.\n",
            "   Normalized numeric columns.\n",
            "\n",
            "Creating Features...\n",
            "   Created 'Family' column.\n",
            "   Created 'LastName' column.\n",
            "THIS IS MY SET {'Compton', 'Moussa', 'Karlsson', 'Bowerman', 'Nicholson', 'Bissette', 'Vande Velde', 'Tomlin', 'Lulic', 'Hewlett', 'Frost', 'Goodwin', 'de Pelsmaeker', 'Widegren', 'Seward', 'Elias', 'Eitemiller', 'Stahelin-Maeglin', 'Potter', 'Staneff', 'Blank', 'Gilinski', 'Lindell', 'Widener', 'Farrell', 'Simonius-Blumer', 'White', 'Mellors', 'Asim', 'Mitchell', 'Pavlovic', 'Calic', 'Murdlin', 'Behr', 'Olsen', 'Pengelly', 'Osman', 'Stone', 'Toufik', 'Laroche', 'Mack', 'Niskanen', 'Trout', 'Beavan', 'Dodge', 'Bailey', 'Hakkarainen', 'Murphy', 'Yasbeck', 'Harder', 'Salonen', \"O'Driscoll\", 'Nysveen', 'Thorneycroft', 'Carlsson', 'Greenfield', 'Collyer', 'Keefe', 'Baclini', 'Hedman', 'Stoytcheff', 'Abbing', 'Woolner', 'Ilett', 'Funk', 'Dahlberg', 'Reeves', 'Thayer', 'Hassab', 'Turcin', 'Zabour', 'Quick', 'Padro y Manent', 'Wheadon', 'Bjornstrom-Steffansson', 'Healy', 'Johansson', 'Vande Walle', 'Hagland', 'Chapman', 'Kelly', 'Rintamaki', \"O'Sullivan\", 'Graham', 'Alexander', 'Banfield', 'Vestrom', 'Vander Cruyssen', 'Denkoff', 'Silvey', 'Christy', 'Davidson', 'Shellard', 'Palsson', 'Dakic', 'Nasser', 'Toomey', 'Coleff', 'Goncalves', 'Watson', 'Lindqvist', 'Sdycoff', 'Sheerlinck', 'Meek', 'Horgan', 'Duane', 'Markoff', 'Pernot', 'Giglio', 'Bradley', 'Lennon', 'Johnson', 'Andersson', 'Sobey', 'Beane', 'Molson', 'Mellinger', 'Peter', 'Laleff', 'Robbins', 'Samaan', 'Parrish', 'Lovell', 'Icard', 'del Carlo', 'Cardeza', 'Ekstrom', 'Lemore', 'Barah', 'Lesurer', 'Stephenson', 'Ali', 'Yrois', 'Leinonen', 'Tikkanen', 'Sirayanian', 'Barber', 'Tobin', 'Sloper', 'Mallet', 'Alhomaki', 'Celotti', 'Doling', 'Foo', 'Ahlin', 'Leeni', 'Kirkland', 'Connolly', 'Rothes', 'Culumovic', 'McGough', 'Hale', 'Ostby', 'Nirva', 'Cumings', 'Ball', 'Marvin', 'Goldschmidt', 'Mineff', 'Rogers', 'Ross', 'Spedden', 'Myhrman', 'Sutehall', 'Simmons', 'Zimmerman', 'Allison', 'Frauenthal', 'Rush', 'Ford', 'Scanlan', 'Moore', 'Birkeland', 'Moss', 'Bing', 'Wright', 'Madigan', 'Richards', 'Balkic', 'Pain', 'Meyer', 'Boulos', 'Garfirth', 'Braund', 'Klaber', 'Burke', 'Yousif', 'Calderhead', 'Betros', 'Meanwell', 'Robert', 'Charters', 'Hood', 'Maioni', 'Wiklund', 'Aubart', 'Elsbury', 'Cherry', 'Weir', 'McNamee', 'Vander Planke', 'Torber', 'McCoy', 'Mitkoff', 'Angle', 'Adams', 'Jonsson', 'Najib', 'Coutts', 'Strom', 'Cairns', 'Coelho', 'Artagaveytia', 'Slabenoff', 'Troutt', 'Madsen', 'Thorne', 'Peuchen', 'Smith', 'Stranden', 'Renouf', 'Mamee', 'Jansson', 'Duff Gordon', 'Klasen', 'Karun', 'Carter', 'Pasic', 'Rood', 'Perreault', 'Doharr', 'Dantcheff', 'Holm', 'Chronopoulos', 'Frolicher-Stehli', 'Nilsson', 'Long', 'Cunningham', 'McCarthy', 'Homer', 'Millet', 'Ohman', 'Morley', 'Clarke', 'Garside', 'Lurette', 'Warren', 'Douglas', 'Becker', 'Beesley', 'Isham', 'Carr', 'Salkjelsvik', 'Drazenoic', 'Bowen', 'Drew', 'Peters', 'Hold', 'Hamalainen', 'Svensson', 'McGowan', 'Bracken', 'Marechal', 'Gronnestad', 'Cor', 'Chibnall', 'Natsch', 'Silven', 'Ibrahim Shawah', 'Harper', 'Humblen', 'Connaghton', 'Petranec', 'Montvila', 'Baxter', 'Sawyer', 'Augustsson', 'Kantor', 'Kiernan', 'Osen', 'Paulner', 'Mullens', 'Turkula', 'Pinsky', \"O'Leary\", 'Sjoblom', 'Radeff', 'Vovk', 'Bidois', 'Uruchurtu', 'Bourke', 'Kallio', 'Lester', 'Saundercock', 'Coxon', 'Cook', 'Larsson', 'Nenkoff', 'Dick', 'Brown', 'Haas', 'Sagesser', 'Shorney', 'Jarvis', 'Dooley', 'Ayoub', 'Naidenoff', 'Johanson', 'Fox', 'Laitinen', 'Hodges', 'Harris', 'Ringhini', 'Devaney', 'Norman', 'Andersen-Jensen', 'Mudd', 'Sivola', 'Emanuel', 'LeRoy', 'Longley', 'Wells', 'Barbara', 'Sharp', 'Sirota', 'Jussila', 'Gavey', 'Endres', 'Watt', 'Kink', 'Kilgannon', 'Skoog', 'Burns', 'Lievens', 'Aks', 'Petterson', 'Harmer', 'Phillips', 'Anderson', 'de Messemaeker', 'Mionoff', 'Gale', 'Moen', 'Ling', 'Allen', 'Dimic', 'Albimona', 'Hosono', 'Lahoud', 'Nankoff', \"O'Dwyer\", 'Fry', 'Nosworthy', 'Kimball', 'Parkes', 'Nicholls', 'Mockler', 'Lam', 'Mannion', 'Strandberg', 'Robins', 'Sinkkonen', 'Bryhl', 'Rommetvedt', 'Chip', 'Pekoniemi', 'Ilmakangas', 'Parr', 'Ivanoff', 'Honkanen', 'Sunderland', 'Lehmann', 'Gilnagh', 'Hampe', 'Cacic', 'Davison', 'Eustis', 'Shutes', 'Jerwan', 'Berglund', 'Theobald', 'Moran', 'Goldenberg', 'Rouse', 'Panula', 'Sjostedt', 'Matthews', 'McDermott', 'Hansen', 'Moor', 'van Melkebeke', 'Lindahl', 'Somerton', 'Butler', 'Lemberopolous', 'Slayter', 'Partner', 'Brocklebank', 'Cleaver', 'Olsson', 'Givard', 'Johannesen-Bratthammer', 'Peduzzi', 'Willey', 'McEvoy', 'Berriman', 'Hickman', 'Webber', 'Collander', 'Adahl', 'Ridsdale', 'Hendekovic', 'Jacobsohn', 'Crease', 'Andreasson', 'Buss', 'Byles', 'Lines', 'Maisner', 'Risien', 'Hegarty', 'Minahan', 'Ryerson', 'Thomas', 'Futrelle', 'Harrison', 'Stead', 'Williams-Lambert', 'Andrews', 'Stankovic', 'Penasco y Castellana', 'Allum', 'Louch', 'Greenberg', 'Pickard', 'Hassan', 'Dean', 'Saalfeld', 'Daly', 'Smart', 'Appleton', 'Duran y More', 'Nysten', 'Oreskovic', 'Taussig', 'Keane', 'Goldsmith', 'Christmann', 'Silverthorne', 'Coleridge', 'Harrington', 'Serepeca', 'Walker', 'Karaic', 'Clifford', 'Caram', 'Baumann', 'West', 'Saad', 'Fleming', 'Dennis', 'Bazzani', 'Otter', 'Soholt', 'Emir', 'Gill', 'Davies', 'Levy', 'Weisz', 'Jermyn', 'Kenyon', 'Caldwell', 'Turpin', 'Taylor', 'Hirvonen', 'Ryan', \"O'Connor\", 'Mernagh', 'Pears', 'Jalsevac', 'Markun', 'Fynney', 'Kvillner', 'Pettersson', 'Canavan', 'Francatelli', 'Porter', 'Cohen', 'Romaine', 'Youseff', 'Stewart', 'Heininen', 'Wick', 'Navratil', 'Meo', 'Sandstrom', 'Rekic', 'Hart', 'Madill', 'Moubarek', 'Danbom', 'Davis', 'Bonnell', 'McGovern', 'Smiljanic', 'Foreman', 'Shelley', 'Dowdell', 'Williams', 'Richard', 'Novel', 'Cavendish', 'Barkworth', 'Jensen', 'Newsom', 'Fischer', 'Blackwell', 'Sundman', 'Morrow', 'Chambers', 'Perkin', 'Gaskell', 'Danoff', 'Fahlstrom', 'Sutton', 'Maenpaa', 'Herman', 'van Billiard', 'Turja', 'Rugg', 'Kink-Heilmann', 'Sedgwick', 'Hocking', 'Giles', 'Wiseman', 'Edvardsson', 'Lindblom', 'Kassem', 'Beckwith', 'Leitch', 'Lobb', 'Bystrom', 'Knight', 'Leader', 'Green', 'Odahl', 'Mangan', 'Reynaldo', 'Hunt', 'Patchett', 'Wilhelms', 'Hawksford', 'Carbines', 'Barton', 'Bateman', 'Eklund', 'Gee', 'Vanden Steen', 'Bostandyeff', 'Lahtinen', 'Newell', 'Butt', 'Nicola-Yarred', 'Lang', 'Roebling', 'Henry', 'Hays', 'Rosblom', 'McKane', 'Mayne', 'Persson', 'Brewe', 'Kraeff', 'Yousseff', 'Farthing', 'Lewy', 'Jonkoff', 'Attalah', 'Van der hoef', 'Rothschild', 'Todoroff', 'Crosby', 'Reuchlin', 'Gheorgheff', 'Tornquist', \"O'Brien\", 'Andrew', 'Moutal', 'Reed', 'Windelov', 'Slocovski', 'Bengtsson', 'Moraweck', 'Abbott', 'Backstrom', 'Downton', 'Gustafsson', 'Harknett', 'Carrau', 'Kalvik', 'Stanley', 'Masselmani', 'Hoyt', 'Glynn', 'Ponesell', 'Troupiansky', 'Jenkin', 'Slemen', 'Waelens', 'Hanna', 'Landergren', 'Flynn', 'Lundahl', 'Razi', 'Gallagher', 'Faunthorpe', 'Cameron', 'Lefebre', 'McMahon', 'Hippach', 'Dahl', 'Sadlier', 'Daniel', 'Swift', 'Spencer', 'Petroff', 'Cribb', 'Campbell', 'Colley', 'Chaffee', 'Hogeboom', 'Ward', 'Young', 'Jardin', 'Touma', 'Bishop', 'Fortune', 'Guggenheim', 'Sage', 'Rice', 'Asplund', 'McCormack', 'Arnold-Franchi', 'de Mulder', 'Leyson', 'Corn', 'Heikkinen', 'Astor', 'Nye', 'Cann', 'Olsvigen', 'Van Impe', 'Dorking', 'Nakid', 'Badt', 'Gillespie', 'Frolicher', 'Plotcharsky', 'Holverson', 'Leonard', 'Sivic', 'Milling', 'Abelson', 'Johnston', 'Kent', \"O'Connell\", 'Connors'}\n",
            "Train data=\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0     1.0   \n",
            "1              2         1     0.0   \n",
            "2              3         1     1.0   \n",
            "3              4         1     0.0   \n",
            "4              5         0     1.0   \n",
            "..           ...       ...     ...   \n",
            "886          887         0     0.5   \n",
            "887          888         1     0.0   \n",
            "888          889         0     1.0   \n",
            "889          890         1     0.0   \n",
            "890          891         0     1.0   \n",
            "\n",
            "                                                  Name     Sex       Age  \\\n",
            "0                              Braund, Mr. Owen Harris    male  0.271174   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  0.472229   \n",
            "2                               Heikkinen, Miss. Laina  female  0.321438   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  0.434531   \n",
            "4                             Allen, Mr. William Henry    male  0.434531   \n",
            "..                                                 ...     ...       ...   \n",
            "886                              Montvila, Rev. Juozas    male  0.334004   \n",
            "887                       Graham, Miss. Margaret Edith  female  0.233476   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  0.367921   \n",
            "889                              Behr, Mr. Karl Howell    male  0.321438   \n",
            "890                                Dooley, Mr. Patrick    male  0.396833   \n",
            "\n",
            "     SibSp     Parch            Ticket      Fare     Cabin Embarked    Family  \\\n",
            "0    0.125  0.000000         A/5 21171  0.014151  0.332123        S  0.125000   \n",
            "1    0.125  0.000000          PC 17599  0.139136  0.568493        C  0.125000   \n",
            "2    0.000  0.000000  STON/O2. 3101282  0.015469  0.332123        S  0.000000   \n",
            "3    0.125  0.000000            113803  0.103644  0.828767        S  0.125000   \n",
            "4    0.000  0.000000            373450  0.015713  0.332123        S  0.000000   \n",
            "..     ...       ...               ...       ...       ...      ...       ...   \n",
            "886  0.000  0.000000            211536  0.025374  0.332123        S  0.000000   \n",
            "887  0.000  0.000000            112053  0.058556  0.273973        S  0.000000   \n",
            "888  0.125  0.333333        W./C. 6607  0.045771  0.332123        S  0.458333   \n",
            "889  0.000  0.000000            111369  0.058556  1.000000        C  0.000000   \n",
            "890  0.000  0.000000            370376  0.015127  0.332123        Q  0.000000   \n",
            "\n",
            "      LastName FamCode  \n",
            "0       Braund     183  \n",
            "1      Cumings     154  \n",
            "2    Heikkinen     646  \n",
            "3     Futrelle     424  \n",
            "4        Allen     344  \n",
            "..         ...     ...  \n",
            "886   Montvila     273  \n",
            "887     Graham      83  \n",
            "888   Johnston     663  \n",
            "889       Behr      33  \n",
            "890     Dooley     304  \n",
            "\n",
            "[891 rows x 15 columns]\n",
            "Test data=\n",
            "     PassengerId  Pclass                                          Name  \\\n",
            "0            892     1.0                              Kelly, Mr. James   \n",
            "1            893     1.0              Wilkes, Mrs. James (Ellen Needs)   \n",
            "2            894     0.5                     Myles, Mr. Thomas Francis   \n",
            "3            895     1.0                              Wirz, Mr. Albert   \n",
            "4            896     1.0  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
            "..           ...     ...                                           ...   \n",
            "413         1305     1.0                            Spector, Mr. Woolf   \n",
            "414         1306     0.0                  Oliva y Ocana, Dona. Fermina   \n",
            "415         1307     1.0                  Saether, Mr. Simon Sivertsen   \n",
            "416         1308     1.0                           Ware, Mr. Frederick   \n",
            "417         1309     1.0                      Peter, Master. Michael J   \n",
            "\n",
            "        Sex       Age  SibSp     Parch              Ticket      Fare  \\\n",
            "0      male  0.452723  0.000  0.000000              330911  0.015282   \n",
            "1    female  0.617566  0.125  0.000000              363272  0.013663   \n",
            "2      male  0.815377  0.000  0.000000              240276  0.018909   \n",
            "3      male  0.353818  0.000  0.000000              315154  0.016908   \n",
            "4    female  0.287881  0.125  0.111111             3101298  0.023984   \n",
            "..      ...       ...    ...       ...                 ...       ...   \n",
            "413    male  0.396975  0.000  0.000000           A.5. 3236  0.015713   \n",
            "414  female  0.512066  0.000  0.000000            PC 17758  0.212559   \n",
            "415    male  0.505473  0.000  0.000000  SOTON/O.Q. 3101262  0.014151   \n",
            "416    male  0.396975  0.000  0.000000              359309  0.015713   \n",
            "417    male  0.396975  0.125  0.111111                2668  0.043640   \n",
            "\n",
            "        Cabin Embarked    Family       LastName FamCode  \n",
            "0    0.351167        Q  0.000000          Kelly     707  \n",
            "1    0.351167        S  0.125000         Wilkes     735  \n",
            "2    0.351167        Q  0.000000          Myles     793  \n",
            "3    0.351167        S  0.000000           Wirz     902  \n",
            "4    0.351167        S  0.236111       Hirvonen     931  \n",
            "..        ...      ...       ...            ...     ...  \n",
            "413  0.351167        S  0.000000        Spector     679  \n",
            "414  0.792308        C  0.000000  Oliva y Ocana     978  \n",
            "415  0.351167        S  0.000000        Saether     715  \n",
            "416  0.351167        S  0.000000           Ware     908  \n",
            "417  0.351167        C  0.236111          Peter     722  \n",
            "\n",
            "[418 rows x 14 columns]\n",
            "Use /tmp/tmpz1q4__4o as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7c3b406c1870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset read in 0:00:00.511586. Found 891 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.953005\n",
            "Compiling model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7c3ab29df130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7c3ab29dee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"random_forest_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (14):\n",
            "\tAge\n",
            "\tCabin\n",
            "\tEmbarked\n",
            "\tFamCode\n",
            "\tFamily\n",
            "\tFare\n",
            "\tLastName\n",
            "\tName\n",
            "\tParch\n",
            "\tPassengerId\n",
            "\tPclass\n",
            "\tSex\n",
            "\tSibSp\n",
            "\tTicket\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.         \"Sex\"  0.389085 ################\n",
            "    2.        \"Fare\"  0.238934 #######\n",
            "    3.         \"Age\"  0.196946 ####\n",
            "    4.      \"Pclass\"  0.186400 ####\n",
            "    5. \"PassengerId\"  0.161055 ##\n",
            "    6.       \"Cabin\"  0.147253 ##\n",
            "    7.      \"Ticket\"  0.136758 #\n",
            "    8.      \"Family\"  0.134628 #\n",
            "    9.    \"Embarked\"  0.127971 \n",
            "   10.     \"FamCode\"  0.113818 \n",
            "   11.    \"LastName\"  0.113294 \n",
            "   12.       \"Parch\"  0.112735 \n",
            "   13.       \"SibSp\"  0.110843 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.      \"Sex\" 102.000000 ################\n",
            "    2.   \"Pclass\" 61.000000 #########\n",
            "    3.     \"Fare\" 58.000000 ########\n",
            "    4.    \"Cabin\" 37.000000 #####\n",
            "    5.   \"Family\" 16.000000 ##\n",
            "    6.   \"Ticket\" 10.000000 #\n",
            "    7. \"Embarked\"  6.000000 \n",
            "    8.      \"Age\"  3.000000 \n",
            "    9. \"LastName\"  3.000000 \n",
            "   10.  \"FamCode\"  2.000000 \n",
            "   11.    \"Parch\"  2.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"PassengerId\" 6462.000000 ################\n",
            "    2.        \"Fare\" 4886.000000 ############\n",
            "    3.         \"Age\" 4842.000000 ###########\n",
            "    4.       \"Cabin\" 1165.000000 ##\n",
            "    5.      \"Family\" 1097.000000 ##\n",
            "    6.    \"Embarked\" 933.000000 ##\n",
            "    7.         \"Sex\" 742.000000 #\n",
            "    8.      \"Pclass\" 680.000000 #\n",
            "    9.       \"SibSp\" 431.000000 \n",
            "   10.      \"Ticket\" 327.000000 \n",
            "   11.       \"Parch\" 277.000000 \n",
            "   12.     \"FamCode\" 117.000000 \n",
            "   13.    \"LastName\" 109.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.         \"Sex\" 37842.215609 ################\n",
            "    2.        \"Fare\" 23041.836496 #########\n",
            "    3. \"PassengerId\" 21010.600236 ########\n",
            "    4.         \"Age\" 20217.907080 ########\n",
            "    5.      \"Pclass\" 10938.099066 ####\n",
            "    6.       \"Cabin\" 6529.509228 ##\n",
            "    7.      \"Family\" 5648.143650 #\n",
            "    8.    \"Embarked\" 3795.369088 #\n",
            "    9.      \"Ticket\" 3438.957535 \n",
            "   10.       \"SibSp\" 1711.175429 \n",
            "   11.    \"LastName\" 1206.390439 \n",
            "   12.     \"FamCode\" 1191.877236 \n",
            "   13.       \"Parch\" 1182.771778 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.817059 logloss:0.572407\n",
            "Number of trees: 300\n",
            "Total number of nodes: 44436\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 148.12 StdDev: 10.2371\n",
            "Min: 115 Max: 175 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 115, 118)  1   0.33%   0.33%\n",
            "[ 118, 121)  2   0.67%   1.00%\n",
            "[ 121, 124)  1   0.33%   1.33%\n",
            "[ 124, 127)  1   0.33%   1.67%\n",
            "[ 127, 130)  8   2.67%   4.33% #\n",
            "[ 130, 133)  5   1.67%   6.00% #\n",
            "[ 133, 136) 21   7.00%  13.00% ####\n",
            "[ 136, 139) 12   4.00%  17.00% ##\n",
            "[ 139, 142) 25   8.33%  25.33% ####\n",
            "[ 142, 145) 18   6.00%  31.33% ###\n",
            "[ 145, 148) 57  19.00%  50.33% ##########\n",
            "[ 148, 151) 15   5.00%  55.33% ###\n",
            "[ 151, 154) 51  17.00%  72.33% #########\n",
            "[ 154, 157) 17   5.67%  78.00% ###\n",
            "[ 157, 160) 31  10.33%  88.33% #####\n",
            "[ 160, 163) 14   4.67%  93.00% ##\n",
            "[ 163, 166) 11   3.67%  96.67% ##\n",
            "[ 166, 169)  1   0.33%  97.00%\n",
            "[ 169, 172)  6   2.00%  99.00% #\n",
            "[ 172, 175]  3   1.00% 100.00% #\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 22368 Average: 8.46052 StdDev: 2.89846\n",
            "Min: 1 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  1,  2)   15   0.07%   0.07%\n",
            "[  2,  3)   97   0.43%   0.50%\n",
            "[  3,  4)  445   1.99%   2.49% ##\n",
            "[  4,  5) 1153   5.15%   7.64% ####\n",
            "[  5,  6) 1849   8.27%  15.91% ######\n",
            "[  6,  7) 2536  11.34%  27.25% #########\n",
            "[  7,  8) 2900  12.96%  40.21% ##########\n",
            "[  8,  9) 2951  13.19%  53.41% ##########\n",
            "[  9, 10) 2755  12.32%  65.72% #########\n",
            "[ 10, 11) 2258  10.09%  75.82% ########\n",
            "[ 11, 12) 1832   8.19%  84.01% ######\n",
            "[ 12, 13) 1273   5.69%  89.70% ####\n",
            "[ 13, 14)  997   4.46%  94.16% ###\n",
            "[ 14, 15)  649   2.90%  97.06% ##\n",
            "[ 15, 15]  658   2.94% 100.00% ##\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 22368 Average: 11.9501 StdDev: 13.398\n",
            "Min: 5 Max: 250 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  17) 18654  83.40%  83.40% ##########\n",
            "[  17,  29)  1852   8.28%  91.68% #\n",
            "[  29,  41)   874   3.91%  95.58%\n",
            "[  41,  54)   432   1.93%  97.51%\n",
            "[  54,  66)   224   1.00%  98.52%\n",
            "[  66,  78)   140   0.63%  99.14%\n",
            "[  78,  91)    96   0.43%  99.57%\n",
            "[  91, 103)    51   0.23%  99.80%\n",
            "[ 103, 115)    26   0.12%  99.92%\n",
            "[ 115, 128)    15   0.07%  99.98%\n",
            "[ 128, 140)     1   0.00%  99.99%\n",
            "[ 140, 152)     1   0.00%  99.99%\n",
            "[ 152, 164)     0   0.00%  99.99%\n",
            "[ 164, 177)     0   0.00%  99.99%\n",
            "[ 177, 189)     1   0.00% 100.00%\n",
            "[ 189, 201)     0   0.00% 100.00%\n",
            "[ 201, 214)     0   0.00% 100.00%\n",
            "[ 214, 226)     0   0.00% 100.00%\n",
            "[ 226, 238)     0   0.00% 100.00%\n",
            "[ 238, 250]     1   0.00% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t6462 : PassengerId [NUMERICAL]\n",
            "\t4886 : Fare [NUMERICAL]\n",
            "\t4842 : Age [NUMERICAL]\n",
            "\t1165 : Cabin [NUMERICAL]\n",
            "\t1097 : Family [NUMERICAL]\n",
            "\t933 : Embarked [CATEGORICAL]\n",
            "\t742 : Sex [CATEGORICAL]\n",
            "\t680 : Pclass [NUMERICAL]\n",
            "\t431 : SibSp [NUMERICAL]\n",
            "\t327 : Ticket [CATEGORICAL]\n",
            "\t277 : Parch [NUMERICAL]\n",
            "\t117 : FamCode [CATEGORICAL]\n",
            "\t109 : LastName [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t102 : Sex [CATEGORICAL]\n",
            "\t61 : Pclass [NUMERICAL]\n",
            "\t58 : Fare [NUMERICAL]\n",
            "\t37 : Cabin [NUMERICAL]\n",
            "\t16 : Family [NUMERICAL]\n",
            "\t10 : Ticket [CATEGORICAL]\n",
            "\t6 : Embarked [CATEGORICAL]\n",
            "\t3 : LastName [CATEGORICAL]\n",
            "\t3 : Age [NUMERICAL]\n",
            "\t2 : Parch [NUMERICAL]\n",
            "\t2 : FamCode [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t264 : Sex [CATEGORICAL]\n",
            "\t156 : Fare [NUMERICAL]\n",
            "\t135 : Pclass [NUMERICAL]\n",
            "\t70 : Cabin [NUMERICAL]\n",
            "\t66 : Age [NUMERICAL]\n",
            "\t57 : Ticket [CATEGORICAL]\n",
            "\t43 : Family [NUMERICAL]\n",
            "\t23 : LastName [CATEGORICAL]\n",
            "\t22 : FamCode [CATEGORICAL]\n",
            "\t19 : Embarked [CATEGORICAL]\n",
            "\t15 : PassengerId [NUMERICAL]\n",
            "\t10 : Parch [NUMERICAL]\n",
            "\t5 : SibSp [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t413 : Sex [CATEGORICAL]\n",
            "\t319 : Fare [NUMERICAL]\n",
            "\t232 : Pclass [NUMERICAL]\n",
            "\t220 : Age [NUMERICAL]\n",
            "\t150 : Family [NUMERICAL]\n",
            "\t141 : Cabin [NUMERICAL]\n",
            "\t138 : Ticket [CATEGORICAL]\n",
            "\t112 : PassengerId [NUMERICAL]\n",
            "\t62 : FamCode [CATEGORICAL]\n",
            "\t56 : Embarked [CATEGORICAL]\n",
            "\t51 : LastName [CATEGORICAL]\n",
            "\t34 : SibSp [NUMERICAL]\n",
            "\t30 : Parch [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t606 : Fare [NUMERICAL]\n",
            "\t604 : Age [NUMERICAL]\n",
            "\t530 : Sex [CATEGORICAL]\n",
            "\t433 : PassengerId [NUMERICAL]\n",
            "\t314 : Pclass [NUMERICAL]\n",
            "\t299 : Family [NUMERICAL]\n",
            "\t249 : Cabin [NUMERICAL]\n",
            "\t202 : Ticket [CATEGORICAL]\n",
            "\t132 : Embarked [CATEGORICAL]\n",
            "\t84 : LastName [CATEGORICAL]\n",
            "\t80 : FamCode [CATEGORICAL]\n",
            "\t65 : SibSp [NUMERICAL]\n",
            "\t61 : Parch [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t1766 : Age [NUMERICAL]\n",
            "\t1729 : PassengerId [NUMERICAL]\n",
            "\t1577 : Fare [NUMERICAL]\n",
            "\t675 : Sex [CATEGORICAL]\n",
            "\t600 : Family [NUMERICAL]\n",
            "\t575 : Cabin [NUMERICAL]\n",
            "\t451 : Pclass [NUMERICAL]\n",
            "\t364 : Embarked [CATEGORICAL]\n",
            "\t284 : Ticket [CATEGORICAL]\n",
            "\t188 : SibSp [NUMERICAL]\n",
            "\t130 : Parch [NUMERICAL]\n",
            "\t113 : FamCode [CATEGORICAL]\n",
            "\t105 : LastName [CATEGORICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t19840 : HigherCondition\n",
            "\t2228 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t177 : HigherCondition\n",
            "\t123 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t500 : HigherCondition\n",
            "\t385 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1238 : HigherCondition\n",
            "\t720 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2631 : HigherCondition\n",
            "\t1028 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t7016 : HigherCondition\n",
            "\t1541 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.741071 logloss:9.33273\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.814689 logloss:3.02756\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.815937 logloss:2.17919\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.820426 logloss:1.65197\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.828283 logloss:1.46112\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.822671 logloss:1.2735\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.817059 logloss:1.23534\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.819304 logloss:1.08532\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.823793 logloss:1.04833\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.821549 logloss:1.04356\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.818182 logloss:1.04139\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.823793 logloss:0.968378\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.826038 logloss:0.965823\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.82716 logloss:0.857579\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.822671 logloss:0.786526\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.824916 logloss:0.786913\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.822671 logloss:0.786584\n",
            "\ttrees: 172, Out-of-bag evaluation: accuracy:0.822671 logloss:0.749439\n",
            "\ttrees: 182, Out-of-bag evaluation: accuracy:0.822671 logloss:0.750016\n",
            "\ttrees: 192, Out-of-bag evaluation: accuracy:0.823793 logloss:0.714374\n",
            "\ttrees: 202, Out-of-bag evaluation: accuracy:0.822671 logloss:0.678553\n",
            "\ttrees: 212, Out-of-bag evaluation: accuracy:0.820426 logloss:0.679045\n",
            "\ttrees: 222, Out-of-bag evaluation: accuracy:0.823793 logloss:0.677737\n",
            "\ttrees: 232, Out-of-bag evaluation: accuracy:0.823793 logloss:0.641923\n",
            "\ttrees: 242, Out-of-bag evaluation: accuracy:0.826038 logloss:0.641365\n",
            "\ttrees: 252, Out-of-bag evaluation: accuracy:0.824916 logloss:0.606727\n",
            "\ttrees: 262, Out-of-bag evaluation: accuracy:0.823793 logloss:0.607273\n",
            "\ttrees: 272, Out-of-bag evaluation: accuracy:0.822671 logloss:0.607467\n",
            "\ttrees: 282, Out-of-bag evaluation: accuracy:0.819304 logloss:0.608347\n",
            "\ttrees: 292, Out-of-bag evaluation: accuracy:0.818182 logloss:0.572646\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.817059 logloss:0.572407\n",
            "\n",
            "None\n",
            "\n",
            "['Sex', 'Fare', 'Age', 'Family', 'Pclass', 'Name', 'Ticket', 'Cabin', 'Embarked', 'PassengerId', 'FamCode']\n",
            "RandomForest200: 0.730594 (0.024000)\n",
            "LinearSVC: 0.837254 (0.024402)\n",
            "MultinomialNB: 0.692442 (0.021026)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic: 0.813678 (0.026540)\n",
            "KNN5: 0.585914 (0.028027)\n",
            "SVCLinear: 0.830538 (0.021639)\n",
            "SVCgamma2: 0.616163 (0.002325)\n",
            "DecisionTree5: 0.819315 (0.019485)\n",
            "AdaBoost: 0.806980 (0.024060)\n",
            "HistGradientBoost: 0.818191 (0.025451)\n",
            "GradientBoosting: 0.820432 (0.030322)\n",
            "Bagging: 0.829396 (0.033489)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicting...\n",
            "   Using Features: ['Sex', 'Fare', 'Age', 'SibSp', 'Parch']\n",
            "     PassengerId  Survived\n",
            "0            892         0\n",
            "1            893         0\n",
            "2            894         0\n",
            "3            895         0\n",
            "4            896         1\n",
            "..           ...       ...\n",
            "413         1305         0\n",
            "414         1306         1\n",
            "415         1307         0\n",
            "416         1308         0\n",
            "417         1309         0\n",
            "\n",
            "[418 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function calls below #\n",
        "\n",
        "# Wrangling #\n",
        "print('\\nWrangling...')\n",
        "wrangleQ0(trainData, testData)\n",
        "#wrangleDelNull(trainData, testData)\n",
        "wrangleNorm(trainData, testData, exclude=[\"PassengerId\"])\n",
        "#printData()\n",
        "\n",
        "# Feature Enginering #\n",
        "print('\\nCreating Features...')\n",
        "family(trainData, testData)\n",
        "lastName(trainData, testData)\n",
        "makeFamCodes(trainData, testData)\n",
        "printData()\n",
        "#printData()\n",
        "\n",
        "# feature sets! #\n",
        "features = [\"Sex\",\"Fare\",\"Age\",\"SibSp\",\"Parch\"]\n",
        "features1 = [\"Sex\",\"Fare\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Embarked\"]\n",
        "features2 = [\"Sex\",\"Fare\",\"Age\",\"Family\",\"Pclass\",\"Ticket\",\"Cabin\",\"Embarked\",\"FamCode\"]\n",
        "featuresALL = [\"Sex\",\"Fare\",\"Age\",\"Family\",\"Pclass\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"PassengerId\",\"FamCode\"]\n",
        "\n",
        "predictImportance(trainData)\n",
        "#testModels(trainData,features)\n",
        "#testModels(trainData, features1)\n",
        "#testModels(trainData, features2)\n",
        "testModels(trainData, featuresALL)\n",
        "\n",
        "# For submissions #\n",
        "print('\\nPredicting...')\n",
        "#prediction = outPrediction(trainData, testData)\n",
        "predictionsList = outputPredictionsList(trainData,testData,features)\n",
        "#print(predictionsList)\n",
        "concensus = outputConcensus(predictionsList)\n",
        "#print(concensus)\n",
        "modelToCSV(testData,concensus)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}